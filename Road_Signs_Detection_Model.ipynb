{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Road Sign detection model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# useful libraries\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import models, layers\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "print('Tensorflow version :', tf.__version__)\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data and check shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "with open(\"./traffic-signs-data/train.p\", mode='rb') as training_data:\n",
    "    train = pickle.load(training_data)\n",
    "with open(\"./traffic-signs-data/valid.p\", mode='rb') as validation_data:\n",
    "    valid = pickle.load(validation_data)\n",
    "with open(\"./traffic-signs-data/test.p\", mode='rb') as testing_data:\n",
    "    test = pickle.load(testing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label and features\n",
    "x_train, y_train = train['features'], train['labels']\n",
    "x_validation, y_validation = valid['features'], valid['labels']\n",
    "x_test, y_test = test['features'], test['labels']\n",
    "\n",
    "# check the shape of the data\n",
    "x_shape = x_train.shape\n",
    "x_val_shape = x_validation.shape\n",
    "\n",
    "print(\"x_training shape :\", x_shape)\n",
    "print(\"x_validation shape :\", x_val_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "x_train, y_train = shuffle(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to grayscale and normalization of the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# convert color images to grayscale using averaging method (np.sum)\n",
    "x_train_gray = np.sum(x_train, axis=3, keepdims=True)/3\n",
    "x_test_gray  = np.sum(x_test, axis=3, keepdims=True)/3\n",
    "x_validation_gray  = np.sum(x_validation, axis=3, keepdims=True)/3\n",
    "\n",
    "# normalization of the data\n",
    "x_train_gray_norm = (x_train_gray)/255.0\n",
    "x_test_gray_norm = (x_test_gray)/255.0\n",
    "x_validation_gray_norm = (x_validation_gray)/255.0\n",
    "\n",
    "# one-hot encoding classes\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "y_validation = to_categorical(y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the data\n",
    "i = 610\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(x_train_gray_norm[i].squeeze(), cmap='gray')\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(x_train[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model architecture\n",
    "\n",
    "After normalization of the data, we've one-hot encoded the 43 different classes of road signs. Now we'll define a model architecture to train our network and to prevent overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import regularizers\n",
    "\n",
    "# Model architecture\n",
    "def cnn_model_architecture(kernel_size, input_shape, batch_size, epochs):\n",
    "            \n",
    "    cnn_model = tf.keras.Sequential()\n",
    "           \n",
    "    cnn_model.add(layers.Conv2D(32, kernel_size, activation = 'relu', kernel_regularizer=regularizers.l2(0.001), input_shape=input_shape)) \n",
    "    cnn_model.add(layers.MaxPooling2D(pool_size=(2,2))) \n",
    "    cnn_model.add(layers.Dropout(0.5))\n",
    "    cnn_model.add(layers.Conv2D(64, kernel_size, activation='relu', kernel_regularizer=regularizers.l2(0.001), input_shape=input_shape))      \n",
    "    cnn_model.add(layers.MaxPooling2D(pool_size=(2,2))) \n",
    "    cnn_model.add(layers.Conv2D(64, kernel_size, activation='relu', kernel_regularizer=regularizers.l2(0.001), input_shape=input_shape)) \n",
    "    cnn_model.add(layers.MaxPooling2D(pool_size=(2,2)))        \n",
    "    cnn_model.add(layers.Dropout(0.5))\n",
    "\n",
    "    cnn_model.add(layers.Flatten())   \n",
    "    cnn_model.add(layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.001))) \n",
    "    cnn_model.add(layers.Dropout(0.5))   \n",
    "    cnn_model.add(layers.Dense(43, activation='softmax'))\n",
    "    \n",
    "    return cnn_model   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model \n",
    "def compile_model():\n",
    "    cnn_model_architecture(kernel_size, input_shape, batch_size, epochs)    \n",
    "    cnn_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
    "    return cnn_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_size = (3,3)\n",
    "input_shape = x_train_gray_norm[1].shape\n",
    "batch_size = 100\n",
    "epochs = 300\n",
    "\n",
    "cnn_model = cnn_model_architecture(kernel_size, input_shape, batch_size, epochs)\n",
    "cnn_model = compile_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, x_train, y_train, x_validation, y_validation):   \n",
    "\n",
    "    # train the model    \n",
    "    history = model.fit(x_train,\n",
    "                        y_train,\n",
    "                        batch_size= batch_size,\n",
    "                        epochs = epochs, \n",
    "                        steps_per_epoch = len(x_train) / batch_size,\n",
    "                        verbose=1, \n",
    "                        validation_data= (x_validation, y_validation))\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train and evaluate the model\n",
    "history = train_model(cnn_model,\n",
    "                                   x_train_gray_norm, \n",
    "                                   y_train, \n",
    "                                   x_validation_gray_norm, \n",
    "                                   y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model\n",
    "score = cnn_model.evaluate(x_test_gray_norm, y_test, verbose=1)\n",
    "print('\\nTest loss : {:.4f}'.format(score[0]))\n",
    "print('Test Accuracy : {:.4f}'.format(score[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot loss _values\n",
    "history_dict = history.history\n",
    "\n",
    "loss_values = history_dict['loss']\n",
    "val_loss_values = history_dict['val_loss']\n",
    "epochs = range(1, len(loss_values)+ 1)\n",
    "line1 = plt.plot(epochs, val_loss_values, label = 'Validation Loss')\n",
    "line2 = plt.plot(epochs, loss_values, label= 'Training Loss')\n",
    "plt.setp(line1, linewidth=2.0, marker = '+', markersize=10.0)\n",
    "plt.setp(line2, linewidth=2.0, marker= '4', markersize=10.0)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plot accuracy \n",
    "\n",
    "acc_values = history_dict['acc']\n",
    "val_acc_values = history_dict['val_acc']\n",
    "epochs = range(1, len(loss_values)+ 1)\n",
    "line1 = plt.plot(epochs, val_acc_values, label = 'Validation Accuracy')\n",
    "line2 = plt.plot(epochs, acc_values, label= 'Training Accuracy')\n",
    "plt.setp(line1, linewidth=2.0, marker = '+', markersize=10.0)\n",
    "plt.setp(line2, linewidth=2.0, marker= '4', markersize=10.0)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "cnn_model.save(\"./road_sign_model_2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "<!-- Save the notebook -->\n",
    "IPython.notebook.save_checkpoint();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "IPython.notebook.session.delete();\n",
    "window.onbeforeunload = null\n",
    "setTimeout(function() { window.close(); }, 1000);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
